{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eebbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "from src.classes.Dataset import MRIDataset, MRISubset\n",
    "from src.classes.Models import ResNet50variant\n",
    "from src.config import PATH_TO_DATASET_CSV, PATH_TO_DATASET, PATH_TO_MODELS, PATH_TO_OUTPUT\n",
    "from src.functions.train_eval import evaluate\n",
    "from src.functions.utils_train import class_results"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training and Evaluation",
   "id": "6bc3cff5701c830f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280511dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input path for images\n",
    "input_path = PATH_TO_DATASET\n",
    "\n",
    "# Load the dataset from a CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(PATH_TO_DATASET_CSV, sep=';', header=0)\n",
    "\n",
    "# List of class names\n",
    "class_names = ['healthy', 'affected']\n",
    "\n",
    "# Create a dictionary that maps class ID to class name\n",
    "id2name = {idx: c for idx, c in enumerate(class_names)}\n",
    "\n",
    "# Create a dictionary where the key is the image index and the value is a tuple of the image path and the corresponding label\n",
    "data = {\n",
    "    idx: (os.path.join(input_path, id2name[row['label']], str(row['img_name'])), row['label'])\n",
    "    for idx, row in df.iterrows()\n",
    "}\n",
    "\n",
    "# Convert labels to a numpy array\n",
    "y = df['label'].to_numpy()\n",
    "\n",
    "# Convert group information to a numpy array\n",
    "groups = df['group'].to_numpy()\n",
    "\n",
    "# Set the number of folds for cross-validation\n",
    "k_folds = 5\n",
    "\n",
    "# Create a StratifiedGroupKFold generator to split the data while preserving the class distribution and group structure\n",
    "sgkf = StratifiedGroupKFold(n_splits=k_folds, shuffle=True, random_state=7)\n",
    "\n",
    "# Convert the dictionary keys to a numpy array (these represent the indices of the images)\n",
    "X = np.array(list(data.keys()))\n",
    "\n",
    "# Generate the train-test split based on the StratifiedGroupKFold\n",
    "train_index, test_index = next(sgkf.split(X, y, groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available, otherwise fallback to CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define test data transformations\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToDtype(torch.float32),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load the pre-trained model\n",
    "path_to_model = os.path.join(PATH_TO_MODELS, \"resnet50v.pth\")\n",
    "model = ResNet50variant()\n",
    "model.load_state_dict(torch.load(path_to_model, map_location=device))\n",
    "\n",
    "# Create the dataset\n",
    "dataset = MRIDataset(data)\n",
    "\n",
    "# Define class names and mapping dictionary\n",
    "class_names = ['healthy', 'affected']\n",
    "id2name = {idx: c for idx, c in enumerate(class_names)}\n",
    "\n",
    "# Create the test dataset subset with transformations applied\n",
    "test_dataset = MRISubset(Subset(dataset, test_index), train_bool=False, transform=test_transforms)\n",
    "\n",
    "# Create a dataloader for the test set\n",
    "dataloaders = {\"test\": DataLoader(test_dataset, batch_size=32)}\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "res = evaluate(model, dataloaders[\"test\"])\n",
    "\n",
    "# Print the classification results\n",
    "class_results(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314982c3",
   "metadata": {},
   "source": "## Analysis of CAM Methods"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dff491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_image(model, cam, img, target=None, transform=None, plot=False):\n",
    "    \"\"\"\n",
    "    Generates a Class Activation Map (CAM) for a given image.\n",
    "\n",
    "    :param model: Trained PyTorch model.\n",
    "    :param cam: GradCAM object.\n",
    "    :param img: Input image tensor.\n",
    "    :param target: Target class label. If None, uses model prediction.\n",
    "    :param transform: Image transformation function.\n",
    "    :param plot: If True, displays the CAM visualization.\n",
    "    :return: Processed CAM image.\n",
    "    \"\"\"\n",
    "    test_img = img.unsqueeze(0)\n",
    "    if target is None:\n",
    "        target = evaluate_img(model, test_img).item()\n",
    "    target = [ClassifierOutputTarget(target)]\n",
    "    grayscale_cams = cam(input_tensor=test_img, targets=target)\n",
    "    grayscale_cam = grayscale_cams[0]\n",
    "\n",
    "    if transform:\n",
    "        img = transform(img)\n",
    "\n",
    "    rgb_img = img.repeat(3, 1, 1).numpy().transpose((1, 2, 0))\n",
    "    cam_img = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(rgb_img)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(cam_img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return cam_img\n",
    "\n",
    "\n",
    "def save_cam(test, data, output_path, model, cam):\n",
    "    \"\"\"\n",
    "    Generates and saves CAM images for a dataset.\n",
    "\n",
    "    :param test: Dataset subset.\n",
    "    :param data: Dictionary mapping indices to image paths and labels.\n",
    "    :param output_path: Directory to save CAM images.\n",
    "    :param model: Trained PyTorch model.\n",
    "    :param cam: GradCAM object.\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_path):\n",
    "        shutil.rmtree(output_path)\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        img, label = test[i]\n",
    "        test_idx = test.subset.indices[i]\n",
    "        path, _ = data[test_idx]\n",
    "        name = os.path.basename(path)\n",
    "        pred = evaluate_img(model, img.unsqueeze(0)).item()\n",
    "        cam_img = cam_image(model, cam, img, target=pred)\n",
    "\n",
    "        subdir = id2name[pred]\n",
    "        final_output_path = os.path.join(output_path, subdir)\n",
    "        os.makedirs(final_output_path, exist_ok=True)\n",
    "\n",
    "        cv2.imwrite(os.path.join(final_output_path, name), cv2.cvtColor(cam_img, cv2.COLOR_RGB2BGR))\n",
    "    print('Save completed')\n",
    "\n",
    "\n",
    "def save_cam_array(test, data, output_path, model, cam):\n",
    "    \"\"\"\n",
    "    Saves CAM images as numpy arrays for further processing.\n",
    "\n",
    "    :param test: Dataset subset.\n",
    "    :param data: Dictionary mapping indices to image paths and labels.\n",
    "    :param output_path: Directory to save CAM numpy arrays.\n",
    "    :param model: Trained PyTorch model.\n",
    "    :param cam: GradCAM object.\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_path):\n",
    "        shutil.rmtree(output_path)\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        img, label = test[i]\n",
    "        test_idx = test.subset.indices[i]\n",
    "        path, _ = data[test_idx]\n",
    "        name = os.path.basename(path)\n",
    "\n",
    "        pred = evaluate_img(model, img.unsqueeze(0)).item()\n",
    "        test_img = img.unsqueeze(0)\n",
    "        target = [ClassifierOutputTarget(pred)]\n",
    "        grayscale_cams = cam(input_tensor=test_img, targets=target)\n",
    "        grayscale_cam = grayscale_cams[0]\n",
    "\n",
    "        np.save(os.path.join(output_path, f'{name}.npy'), grayscale_cam)\n",
    "    print('Save completed')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GradCAM",
   "id": "5f6b61c540c2843"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea608062",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = [model.conv]\n",
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "output_path = os.path.join(PATH_TO_OUTPUT, 'GradCAM')\n",
    "preds, labels = save_cam(test, data, output_path, model, cam)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GradCAM++",
   "id": "5aaa727b0e0408d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c55481",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = [model.conv]\n",
    "cam = GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
    "\n",
    "output_path = os.path.join(PATH_TO_OUTPUT, 'GradCAMPlusPlus')\n",
    "save_cam(test, data, output_path, model, cam)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## HiresCAM",
   "id": "7c8cdc0bfb23bd75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad47b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = [model.conv]\n",
    "cam = HiResCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "output_path = os.path.join(PATH_TO_OUTPUT, 'HiResCAM')\n",
    "save_cam(test, data, output_path, model, cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0041607a",
   "metadata": {},
   "source": [
    "## Occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3374d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_occlusion(model, image, target_class, stride, window_size, min_window_size, x_start, y_start, x_end,\n",
    "                           y_end, zero=False):\n",
    "    \"\"\"\n",
    "    Applies hierarchical occlusion on the image to evaluate the importance of each region for the target class.\n",
    "\n",
    "    :param model: The model used for evaluation.\n",
    "    :param image: The image tensor to analyze.\n",
    "    :param target_class: The target class to focus on.\n",
    "    :param stride: The stride of the sliding window.\n",
    "    :param window_size: The initial window size for occlusion.\n",
    "    :param min_window_size: The minimum window size to stop occlusion.\n",
    "    :param x_start, y_start, x_end, y_end: The coordinates defining the area to apply occlusion on.\n",
    "    :param zero: Whether to zero-out the occluded areas or set them to 1.\n",
    "    :return: The aggregated occlusion map.\n",
    "    \"\"\"\n",
    "    # Start with the initial occlusion map\n",
    "    output, areas = class_occlusion(model, image, target_class, stride, window_size, x_start, y_start, x_end, y_end,\n",
    "                                    None, zero)\n",
    "\n",
    "    # Perform hierarchical occlusion by reducing window size iteratively\n",
    "    while len(areas) > 0 and window_size > min_window_size:\n",
    "        stride = max(stride // 2, 1)  # Reduce stride\n",
    "        window_size = window_size // 2  # Halve the window size\n",
    "        diff_map, areas = class_occlusion(model, image, target_class, stride, window_size, x_start, y_start, x_end,\n",
    "                                          y_end, areas, zero)\n",
    "        output += diff_map  # Accumulate the difference map\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def class_occlusion(model, image, target_class, stride, window_size, x_start, y_start, x_end, y_end, old_areas, zero):\n",
    "    \"\"\"\n",
    "    Performs class occlusion on an image and computes the difference map by occluding different regions.\n",
    "\n",
    "    :param model: The model to evaluate.\n",
    "    :param image: The input image tensor.\n",
    "    :param target_class: The class to evaluate the importance of.\n",
    "    :param stride: The stride for the sliding window.\n",
    "    :param window_size: The size of the occlusion window.\n",
    "    :param x_start, y_start, x_end, y_end: The coordinates defining the region of interest.\n",
    "    :param old_areas: Previous occluded areas to consider.\n",
    "    :param zero: Whether to zero out the occluded region or set it to 1.\n",
    "    :return: The difference map and updated areas for further occlusion.\n",
    "    \"\"\"\n",
    "    original_label = evaluate_img(model, image.unsqueeze(0))  # Get the original class prediction\n",
    "\n",
    "    _, H, W = image.shape  # Get the height and width of the image\n",
    "\n",
    "    # Initialize the difference map with zeros\n",
    "    diff_map = np.zeros((H, W), dtype=float)\n",
    "    new_areas = []  # To store newly occluded regions\n",
    "\n",
    "    # Iterate over the image within the specified region, applying the occlusion window\n",
    "    for i in range(y_start, y_end, max(stride, 1)):\n",
    "        y_occlusion_end = min(y_end, i + window_size)  # Ensure occlusion does not exceed bounds\n",
    "        for j in range(x_start, x_end, max(stride, 1)):\n",
    "            x_occlusion_end = min(x_end, j + window_size)\n",
    "\n",
    "            # Check if the current window is inside previously occluded areas\n",
    "            if is_inside(i, j, old_areas, window_size * 2):\n",
    "                # Create a copy of the image for occlusion\n",
    "                occluded_image = image.clone()\n",
    "\n",
    "                # Apply occlusion (zero out or set to 1 based on the 'zero' flag)\n",
    "                if zero:\n",
    "                    occluded_image[:, i:y_occlusion_end, j:x_occlusion_end] = 0\n",
    "                else:\n",
    "                    occluded_image[:, i:y_occlusion_end, j:x_occlusion_end] = 1 if target_class != 1 else 0\n",
    "\n",
    "                # Predict the class after occlusion\n",
    "                occluded_label = evaluate_img(model, occluded_image.unsqueeze(0))\n",
    "\n",
    "                # Calculate the absolute difference in class probability\n",
    "                diff = abs(original_label - occluded_label)\n",
    "                diff_map[i:y_occlusion_end, j:x_occlusion_end] = np.maximum(diff, diff_map[i:y_occlusion_end,\n",
    "                                                                                  j:x_occlusion_end])\n",
    "\n",
    "                # If the difference is significant, store the area for further occlusion\n",
    "                if diff == 1:\n",
    "                    new_areas.append((i, j))\n",
    "\n",
    "    return diff_map, new_areas  # Return the updated difference map and areas\n",
    "\n",
    "\n",
    "def is_inside(y, x, areas, window_size):\n",
    "    \"\"\"\n",
    "    Checks if the given position (y, x) is inside any of the previously occluded areas.\n",
    "\n",
    "    :param y, x: The position to check.\n",
    "    :param areas: List of previously occluded areas.\n",
    "    :param window_size: The size of the occlusion window.\n",
    "    :return: True if inside any area, False otherwise.\n",
    "    \"\"\"\n",
    "    if areas is None:  # For the first iteration, all positions are valid\n",
    "        return True\n",
    "    for (ay, ax) in areas:\n",
    "        if ay <= y < ay + window_size and ax <= x < ax + window_size:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a426e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_occlusion_heatmap(model, test_data, data):\n",
    "    \"\"\"\n",
    "    Applies the occlusion heatmap to the test dataset images using the specified model.\n",
    "    \"\"\"\n",
    "    stats = {\"p1\": 0, \"p0\": 0, \"count_affected\": 0, \"count_healthy\": 0}\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        img, label = test_data[i]\n",
    "        test_idx = test_data.subset.indices[i]\n",
    "        path, _ = data[test_idx]\n",
    "        name = path.split('\\\\')[-1]\n",
    "\n",
    "        _, H, W = img.shape\n",
    "        pred = evaluate_img(model, img.unsqueeze(0)).item()\n",
    "\n",
    "        rgb_img = img.repeat(3, 1, 1).numpy().transpose((1, 2, 0))\n",
    "\n",
    "        occlusion_map = load_occlusion_map(name, \"Resnet18v\", suffix=\"\" if pred == 1 else \"-2\")\n",
    "        if np.any(occlusion_map >= 1):\n",
    "            stats[\"count_affected\" if pred == 1 else \"count_healthy\"] += 1\n",
    "        else:\n",
    "            occlusion_map = np.zeros((H, W), dtype=float)\n",
    "\n",
    "        stats[\"p1\" if pred == 1 else \"p0\"] += 1\n",
    "        display_heatmap(rgb_img, occlusion_map, name)\n",
    "\n",
    "    print(\n",
    "        f\"Pred 1: {stats['p1']}, Pred 0: {stats['p0']}, Count 1: {stats['count_affected']}, Count 0: {stats['count_healthy']}\")\n",
    "\n",
    "\n",
    "def hierarchical_occlusion_with_params(model, test_data, data):\n",
    "    \"\"\"\n",
    "    Computes hierarchical occlusion with different parameters for images without occlusion output.\n",
    "    \"\"\"\n",
    "    stats = {\"p1\": 0, \"p0\": 0, \"count_affected\": 0, \"count_healthy\": 0}\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        img, label = test_data[i]\n",
    "        test_idx = test_data.subset.indices[i]\n",
    "        path, _ = data[test_idx]\n",
    "        name = path.split('\\\\')[-1]\n",
    "\n",
    "        _, H, W = img.shape\n",
    "        pred = evaluate_img(model, img.unsqueeze(0)).item()\n",
    "\n",
    "        rgb_img = img.repeat(3, 1, 1).numpy().transpose((1, 2, 0))\n",
    "        occlusion_map = load_or_compute_occlusion(name, \"Resnet18v\", PATH_TO_MODELS, img, pred, H, W,\n",
    "                                                  suffix=\"\" if pred == 1 else \"-2\")\n",
    "        if np.any(occlusion_map >= 1):\n",
    "            stats[\"count_affected\" if pred == 1 else \"count_healthy\"] += 1\n",
    "\n",
    "        stats[\"p1\" if pred == 1 else \"p0\"] += 1\n",
    "        display_heatmap(rgb_img, occlusion_map, name)\n",
    "\n",
    "    print(\n",
    "        f\"Pred 1: {stats['p1']}, Pred 0: {stats['p0']}, Count 1: {stats['count_affected']}, Count 0: {stats['count_healthy']}\")\n",
    "\n",
    "\n",
    "def load_occlusion_map(name, model_variant, suffix=\"\"):\n",
    "    map_path = os.path.join(PATH_TO_MODELS, model_variant, f\"{name}{suffix}.npy\")\n",
    "    return normalize(np.load(map_path)) if os.path.exists(map_path) else np.zeros((256, 256), dtype=float)\n",
    "\n",
    "\n",
    "def load_or_compute_occlusion(name, model_variant, img, pred, H, W, suffix=\"\"):\n",
    "    map_path = os.path.join(PATH_TO_MODELS, \"Occlusion2\" if pred == 1 else \"Occlusion4\", model_variant,\n",
    "                            f\"{name}{suffix}.npy\")\n",
    "    if os.path.exists(map_path):\n",
    "        return normalize(np.load(map_path))\n",
    "    return hierarchical_occlusion(model, img, pred, stride=28, window_size=112, min_window_size=7, x_start=0, y_start=0,\n",
    "                                  x_end=W, y_end=H, zero=True)\n",
    "\n",
    "\n",
    "def display_heatmap(rgb_img, occlusion_map, name):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * occlusion_map), cv2.COLORMAP_PARULA)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    final_img = cv2.addWeighted(rgb_img, 1, heatmap, 0.5, 0)\n",
    "    final_img = normalize(final_img)\n",
    "    plt.imshow(final_img)\n",
    "    plt.title(name)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def normalize(image):\n",
    "    return image / np.max(image) if np.max(image) > 0 else image"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load models\n",
    "m18 = ResNet18variant()\n",
    "m18.load_state_dict(torch.load(os.path.join(PATH_TO_MODELS, \"resnet18v.pth\"), map_location=torch.device('cpu')))\n",
    "\n",
    "m50 = ResNet50variant()\n",
    "m50.load_state_dict(torch.load(os.path.join(PATH_TO_MODELS, \"resnet50v.pth\"), map_location=torch.device('cpu')))\n",
    "\n",
    "# Choose the model (ResNet18 in this case)\n",
    "model = m18\n",
    "\n",
    "# Apply occlusion heatmap to test data\n",
    "apply_occlusion_heatmap(model, test, data)\n",
    "\n",
    "# Apply hierarchical occlusion with different parameters to test data\n",
    "hierarchical_occlusion_with_params(model, test, data)"
   ],
   "id": "91f3e6229565f3c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
